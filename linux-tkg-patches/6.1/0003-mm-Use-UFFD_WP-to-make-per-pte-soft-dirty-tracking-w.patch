From 7cdccc34bff440fdf3a29ddd409192a1f06fc832 Mon Sep 17 00:00:00 2001
From: Paul Gofman <pgofman@codeweavers.com>
Date: Wed, 21 Dec 2022 13:32:27 -0600
Subject: [PATCH 3/3] mm: Use UFFD_WP to make per-pte soft dirty tracking work
 reliably.

This patch has one side-effect that the PM_UFFD_WP bit will not show up
in the pagemap file. Not sure which app can use PM_UFFD_WP. So we are
good.

Signed-off-by: Paul Gofman <pgofman@codeweavers.com>
(cherry picked from commit 3bb954b43e1837b2294486aa4c62e015d35391e5)
Signed-off-by: Cristian Ciocaltea <cristian.ciocaltea@collabora.com>
---
 fs/proc/task_mmu.c | 17 ++---------------
 mm/mprotect.c      |  2 +-
 2 files changed, 3 insertions(+), 16 deletions(-)

diff --git a/fs/proc/task_mmu.c b/fs/proc/task_mmu.c
index 9ff4f46d3ff3..b2795bd98f40 100644
--- a/fs/proc/task_mmu.c
+++ b/fs/proc/task_mmu.c
@@ -1116,10 +1116,12 @@ static inline bool clear_soft_dirty(struct vm_area_struct *vma,
 		ret = pte_soft_dirty(old_pte);
 		ptent = pte_wrprotect(old_pte);
 		ptent = pte_clear_soft_dirty(ptent);
+		ptent = pte_mkuffd_wp(ptent);
 		ptep_modify_prot_commit(vma, addr, pte, old_pte, ptent);
 	} else if (is_swap_pte(ptent)) {
 		ret = pte_swp_soft_dirty(ptent);
 		ptent = pte_swp_clear_soft_dirty(ptent);
+		ptent = pte_swp_mkuffd_wp(ptent);
 		set_pte_at(vma->vm_mm, addr, pte, ptent);
 	}
     return ret;
@@ -1514,14 +1516,10 @@ static pagemap_entry_t pte_to_pagemap_entry(struct pagemapread *pm,
 		page = vm_normal_page(vma, addr, pte);
 		if (pte_soft_dirty(pte))
 			flags |= PM_SOFT_DIRTY | PM_SOFT_DIRTY_PAGE;
-		if (pte_uffd_wp(pte))
-			flags |= PM_UFFD_WP;
 	} else if (is_swap_pte(pte)) {
 		swp_entry_t entry;
 		if (pte_swp_soft_dirty(pte))
 			flags |= PM_SOFT_DIRTY | PM_SOFT_DIRTY_PAGE;
-		if (pte_swp_uffd_wp(pte))
-			flags |= PM_UFFD_WP;
 		entry = pte_to_swp_entry(pte);
 		if (pm->show_pfn) {
 			pgoff_t offset;
@@ -1540,8 +1538,6 @@ static pagemap_entry_t pte_to_pagemap_entry(struct pagemapread *pm,
 		migration = is_migration_entry(entry);
 		if (is_pfn_swap_entry(entry))
 			page = pfn_swap_entry_to_page(entry);
-		if (pte_marker_entry_uffd_wp(entry))
-			flags |= PM_UFFD_WP;
 	}
 
 	if (page && !PageAnon(page))
@@ -1596,8 +1592,6 @@ static int pagemap_pmd_range(pmd_t *pmdp, unsigned long addr, unsigned long end,
 			flags |= PM_PRESENT;
 			if (pmd_soft_dirty(pmd))
 				flags |= PM_SOFT_DIRTY | PM_SOFT_DIRTY_PAGE;
-			if (pmd_uffd_wp(pmd))
-				flags |= PM_UFFD_WP;
 			if (pm->show_pfn)
 				frame = pmd_pfn(pmd) +
 					((addr & ~PMD_MASK) >> PAGE_SHIFT);
@@ -1620,8 +1614,6 @@ static int pagemap_pmd_range(pmd_t *pmdp, unsigned long addr, unsigned long end,
 			flags |= PM_SWAP;
 			if (pmd_swp_soft_dirty(pmd))
 				flags |= PM_SOFT_DIRTY | PM_SOFT_DIRTY_PAGE;
-			if (pmd_swp_uffd_wp(pmd))
-				flags |= PM_UFFD_WP;
 			VM_BUG_ON(!is_pmd_migration_entry(pmd));
 			migration = is_migration_entry(entry);
 			page = pfn_swap_entry_to_page(entry);
@@ -1708,15 +1700,10 @@ static int pagemap_hugetlb_range(pte_t *ptep, unsigned long hmask,
 		if (page_mapcount(page) == 1)
 			flags |= PM_MMAP_EXCLUSIVE;
 
-		if (huge_pte_uffd_wp(pte))
-			flags |= PM_UFFD_WP;
-
 		flags |= PM_PRESENT;
 		if (pm->show_pfn)
 			frame = pte_pfn(pte) +
 				((addr & ~hmask) >> PAGE_SHIFT);
-	} else if (pte_swp_uffd_wp_any(pte)) {
-		flags |= PM_UFFD_WP;
 	}
 
 	for (; addr != end; addr += PAGE_SIZE) {
diff --git a/mm/mprotect.c b/mm/mprotect.c
index 668bfaa6ed2a..27a665e0b524 100644
--- a/mm/mprotect.c
+++ b/mm/mprotect.c
@@ -54,7 +54,7 @@ static inline bool can_change_pte_writable(struct vm_area_struct *vma,
 		return false;
 
 	/* Do we need write faults for uffd-wp tracking? */
-	if (userfaultfd_pte_wp(vma, pte))
+	if (pte_uffd_wp(pte))
 		return false;
 
 	if (!(vma->vm_flags & VM_SHARED)) {
-- 
2.42.0

