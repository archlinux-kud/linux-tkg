From 0135bedfb08bcd9bc45b876e50c9e296a0d18af1 Mon Sep 17 00:00:00 2001
From: Paul Gofman <pgofman@codeweavers.com>
Date: Wed, 21 Dec 2022 13:32:27 -0600
Subject: [PATCH 3/3] mm: Use UFFD_WP to make per-pte soft dirty tracking work
 reliably.

This patch has one side-effect that the PM_UFFD_WP bit will not show up
in the pagemap file. Not sure which app can use PM_UFFD_WP. So we are
good.

Signed-off-by: Paul Gofman <pgofman@codeweavers.com>
(cherry picked from commit 3bb954b43e1837b2294486aa4c62e015d35391e5)
Signed-off-by: Cristian Ciocaltea <cristian.ciocaltea@collabora.com>
---
 fs/proc/task_mmu.c | 17 ++---------------
 mm/mprotect.c      |  2 +-
 2 files changed, 3 insertions(+), 16 deletions(-)

diff --git a/fs/proc/task_mmu.c b/fs/proc/task_mmu.c
index ee3a637e3900..46f6629e618e 100644
--- a/fs/proc/task_mmu.c
+++ b/fs/proc/task_mmu.c
@@ -1113,10 +1113,12 @@ static inline bool clear_soft_dirty(struct vm_area_struct *vma,
 		ret = pte_soft_dirty(old_pte);
 		ptent = pte_wrprotect(old_pte);
 		ptent = pte_clear_soft_dirty(ptent);
+		ptent = pte_mkuffd_wp(ptent);
 		ptep_modify_prot_commit(vma, addr, pte, old_pte, ptent);
 	} else if (is_swap_pte(ptent)) {
 		ret = pte_swp_soft_dirty(ptent);
 		ptent = pte_swp_clear_soft_dirty(ptent);
+		ptent = pte_swp_mkuffd_wp(ptent);
 		set_pte_at(vma->vm_mm, addr, pte, ptent);
 	}
     return ret;
@@ -1511,14 +1513,10 @@ static pagemap_entry_t pte_to_pagemap_entry(struct pagemapread *pm,
 		page = vm_normal_page(vma, addr, pte);
 		if (pte_soft_dirty(pte))
 			flags |= PM_SOFT_DIRTY | PM_SOFT_DIRTY_PAGE;
-		if (pte_uffd_wp(pte))
-			flags |= PM_UFFD_WP;
 	} else if (is_swap_pte(pte)) {
 		swp_entry_t entry;
 		if (pte_swp_soft_dirty(pte))
 			flags |= PM_SOFT_DIRTY | PM_SOFT_DIRTY_PAGE;
-		if (pte_swp_uffd_wp(pte))
-			flags |= PM_UFFD_WP;
 		entry = pte_to_swp_entry(pte);
 		if (pm->show_pfn) {
 			pgoff_t offset;
@@ -1537,8 +1535,6 @@ static pagemap_entry_t pte_to_pagemap_entry(struct pagemapread *pm,
 		migration = is_migration_entry(entry);
 		if (is_pfn_swap_entry(entry))
 			page = pfn_swap_entry_to_page(entry);
-		if (pte_marker_entry_uffd_wp(entry))
-			flags |= PM_UFFD_WP;
 	}
 
 	if (page && !PageAnon(page))
@@ -1593,8 +1589,6 @@ static int pagemap_pmd_range(pmd_t *pmdp, unsigned long addr, unsigned long end,
 			flags |= PM_PRESENT;
 			if (pmd_soft_dirty(pmd))
 				flags |= PM_SOFT_DIRTY | PM_SOFT_DIRTY_PAGE;
-			if (pmd_uffd_wp(pmd))
-				flags |= PM_UFFD_WP;
 			if (pm->show_pfn)
 				frame = pmd_pfn(pmd) +
 					((addr & ~PMD_MASK) >> PAGE_SHIFT);
@@ -1617,8 +1611,6 @@ static int pagemap_pmd_range(pmd_t *pmdp, unsigned long addr, unsigned long end,
 			flags |= PM_SWAP;
 			if (pmd_swp_soft_dirty(pmd))
 				flags |= PM_SOFT_DIRTY | PM_SOFT_DIRTY_PAGE;
-			if (pmd_swp_uffd_wp(pmd))
-				flags |= PM_UFFD_WP;
 			VM_BUG_ON(!is_pmd_migration_entry(pmd));
 			migration = is_migration_entry(entry);
 			page = pfn_swap_entry_to_page(entry);
@@ -1706,15 +1698,10 @@ static int pagemap_hugetlb_range(pte_t *ptep, unsigned long hmask,
 		if (page_mapcount(page) == 1)
 			flags |= PM_MMAP_EXCLUSIVE;
 
-		if (huge_pte_uffd_wp(pte))
-			flags |= PM_UFFD_WP;
-
 		flags |= PM_PRESENT;
 		if (pm->show_pfn)
 			frame = pte_pfn(pte) +
 				((addr & ~hmask) >> PAGE_SHIFT);
-	} else if (pte_swp_uffd_wp_any(pte)) {
-		flags |= PM_UFFD_WP;
 	}
 
 	for (; addr != end; addr += PAGE_SIZE) {
diff --git a/mm/mprotect.c b/mm/mprotect.c
index 81991102f785..e8a21eefef51 100644
--- a/mm/mprotect.c
+++ b/mm/mprotect.c
@@ -56,7 +56,7 @@ bool can_change_pte_writable(struct vm_area_struct *vma, unsigned long addr,
 		return false;
 
 	/* Do we need write faults for uffd-wp tracking? */
-	if (userfaultfd_pte_wp(vma, pte))
+	if (pte_uffd_wp(pte))
 		return false;
 
 	if (!(vma->vm_flags & VM_SHARED)) {
-- 
2.43.0

